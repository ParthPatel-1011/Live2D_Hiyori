<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Live2D AI Companion</title>
    
    <!-- Use compatible PixiJS Version 5 -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/pixi.js/5.3.10/pixi.min.js"></script>
    
    <!-- External CSS -->
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <div id="live2d-container">
        <canvas id="live2d-canvas"></canvas>
        <div id="loading-indicator">Loading Live2D model...</div>
        
        <!-- Fallback UI when model fails to load -->
        <div id="fallback-ui">
            <div id="fallback-avatar">ðŸ¤–</div>
            <h1>AI Companion</h1>
            <p>The Live2D model could not be loaded, but you can still chat with the AI companion. Your messages will be converted to speech and played through your speakers.</p>
        </div>
    </div>
    
    <div id="chat-interface">
        <input type="text" id="message-input" placeholder="Type your message here..." autocomplete="off">
        <button id="send-button">Send</button>
    </div>

    <div id="api-key-modal">
        <div class="modal-content">
            <h2>ElevenLabs API Setup</h2>
            <p>To use this Live2D AI Companion, you need an ElevenLabs API key:</p>
            <ol>
                <li>Create an account at <a href="https://elevenlabs.io/" target="_blank" style="color:#ffa502;">elevenlabs.io</a></li>
                <li>Go to your profile settings and copy your API key</li>
                <li>Paste your API key below</li>
            </ol>
            
            <input type="password" id="api-key-input" placeholder="Enter your ElevenLabs API key">
            <button id="save-api-key">Save API Key</button>
            
            <div class="instructions">
                <h3>Security Note:</h3>
                <p>In a production environment, API keys should never be stored in client-side code. For a secure implementation:</p>
                <ol>
                    <li>Create a backend server (Node.js/Express recommended)</li>
                    <li>Store your API key in a <span class="highlight">.env</span> file on the server</li>
                    <li>Implement an endpoint like <span class="highlight">/generate-speech</span> that proxies requests to ElevenLabs</li>
                    <li>Modify the <span class="highlight">generateSpeech</span> function to call your backend instead of ElevenLabs directly</li>
                </ol>
            </div>
        </div>
    </div>

    <script>
        // Global variables
        let app, model;
        const ELEVENLABS_API_URL = "https://api.elevenlabs.io/v1/text-to-speech";
        const DEFAULT_VOICE_ID = "21m00Tcm4TlvDq8ikWAM"; // Rachel voice
        
        // Expose PIXI to window so that pixi-live2d-display can reference it
        window.PIXI = PIXI;
        
        // Debug information
        console.log('PixiJS version:', PIXI.VERSION);
        console.log('Live2D support:', typeof PIXI.live2d !== 'undefined' ? 'Available' : 'Not available');
        
        // DOM Elements
        const canvas = document.getElementById('live2d-canvas');
        const messageInput = document.getElementById('message-input');
        const sendButton = document.getElementById('send-button');
        const loadingIndicator = document.getElementById('loading-indicator');
        const apiKeyModal = document.getElementById('api-key-modal');
        const apiKeyInput = document.getElementById('api-key-input');
        const saveApiKeyButton = document.getElementById('save-api-key');
        
        // Check for saved API key
        const savedApiKey = localStorage.getItem('elevenlabs-api-key');
        if (savedApiKey) {
            apiKeyModal.style.display = 'none';
        }
        
        // Save API key handler
        saveApiKeyButton.addEventListener('click', () => {
            const apiKey = apiKeyInput.value.trim();
            if (apiKey) {
                localStorage.setItem('elevenlabs-api-key', apiKey);
                apiKeyModal.style.display = 'none';
                // Wait a bit for libraries to fully load before initializing
                setTimeout(initApp, 100);
            } else {
                alert('Please enter a valid API key');
            }
        });
        
        // Dynamically load libraries in the correct order
        async function loadLibraries() {
            console.log('Starting library loading...');
            showLoadingIndicator();
            loadingIndicator.innerHTML = 'Loading libraries...';
            
            try {
                // Load Cubism 2 Core
                await loadScript('https://cdn.jsdelivr.net/gh/dylanNew/live2d/webgl/Live2D/lib/live2d.min.js');
                console.log('Cubism 2 Core loaded');
                
                // Load Cubism 4 Core
                await loadScript('https://cubism.live2d.com/sdk-web/cubismcore/live2dcubismcore.min.js');
                console.log('Cubism 4 Core loaded');
                
                // Load pixi-live2d-display-lipsyncpatch
                await loadScript('https://cdn.jsdelivr.net/npm/pixi-live2d-display-lipsyncpatch/dist/index.min.js');
                console.log('pixi-live2d-display-lipsyncpatch loaded');
                
                console.log('All libraries loaded successfully');
                loadingIndicator.innerHTML = 'Libraries loaded successfully';
            } catch (error) {
                console.error(`Error loading libraries: ${error.message}`);
                loadingIndicator.innerHTML = `Error loading libraries: ${error.message}`;
            }
        }
        
        function loadScript(src) {
            return new Promise((resolve, reject) => {
                const script = document.createElement('script');
                script.src = src;
                script.onload = () => resolve();
                script.onerror = () => reject(new Error(`Failed to load script: ${src}`));
                document.head.appendChild(script);
            });
        }
        
        // Initialize the application
        async function initApp() {
            showLoadingIndicator();
            loadingIndicator.innerHTML = 'Initializing application...';
            
            try {
                // Load libraries dynamically
                await loadLibraries();
                
                // Wait a bit for libraries to fully initialize
                await new Promise(resolve => setTimeout(resolve, 1000));
                
                // Initialize PIXI Application with better settings
                app = new PIXI.Application({
                    view: canvas,
                    transparent: true,
                    autoStart: true,
                    resizeTo: window,
                    antialias: true,
                    resolution: window.devicePixelRatio || 1
                });
                
                // Ensure the view is visible
                app.view.style.display = 'block';
                
                console.log('PIXI Application initialized');
                loadingIndicator.innerHTML = 'PIXI Application initialized';
                
                // Load the local Hiyori model
                try {
                    loadingIndicator.innerHTML = 'Loading Hiyori model...';
                    console.log('Attempting to load local Hiyori model');
                    
                    // Use the correct relative path to your model file
                    const MODEL_PATH = './Hiyori/Hiyori.model3.json'; 
                    
                    model = await PIXI.live2d.Live2DModel.from(MODEL_PATH);
                    console.log('Successfully loaded local Hiyori model');
                    
                } catch (modelError) {
                    console.error('Failed to load local Hiyori model:', modelError);
                    console.warn('The local model failed. This is probably because you are running this as a file (file://) and not on a local server. Trying remote fallbacks...');

                    // Fallback to remote models
                    const modelSources = [
                        // Official Shizuku model (Cubism 2.1)
                        'https://cdn.jsdelivr.net/gh/guansss/pixi-live2d-display/test/assets/shizuku.model.json',
                        // Haru model (Cubism 4)
                        'https://cdn.jsdelivr.net/gh/guansss/pixi-live2d-display/test/assets/haru/haru.model.json'
                    ];
                    
                    let modelLoaded = false;
                    for (const [index, source] of modelSources.entries()) {
                        try {
                            loadingIndicator.innerHTML = `Loading fallback model (${index + 1}/${modelSources.length})...`;
                            console.log(`Attempting to load fallback model from: ${source}`);
                            model = await PIXI.live2d.Live2DModel.from(source);
                            modelLoaded = true;
                            console.log('Successfully loaded fallback model from:', source);
                            break;
                        } catch (error) {
                            console.warn(`Failed to load fallback model from ${source}:`, error);
                        }
                    }
                    
                    if (!modelLoaded) {
                        throw new Error('Failed to load local model AND all fallback models.');
                    }
                }
                
                console.log('Model loaded:', model);
                loadingIndicator.innerHTML = 'Model loaded successfully';
                
                // Add model to stage
                app.stage.addChild(model);
                
                // --- FACE-FOCUSED POSITIONING ---
                // Set the model's anchor point to its center
                model.anchor.set(0.5, 0.5);

                // Position and scale the model with responsive logic
                positionModel();
                
                // Ensure the model is visible
                model.visible = true;
                
                console.log('Model positioned and scaled');
                
                // Start idle animation
                try {
                    console.log('Attempting to start idle motion');
                    // Try multiple motion names
                    const motionNames = ['Idle', 'idle', 'Idle_01', 'idle_01', 'StartIdle', 'motion'];
                    let motionStarted = false;
                    
                    for (const motionName of motionNames) {
                        try {
                            model.motion(motionName);
                            console.log('Started motion:', motionName);
                            motionStarted = true;
                            break;
                        } catch (motionError) {
                            console.warn('Failed to start motion:', motionName, motionError);
                        }
                    }
                    
                    if (!motionStarted) {
                        console.warn('No idle motion could be started');
                    } else {
                        console.log('Idle motion started');
                    }
                } catch (motionError) {
                    console.warn('Failed to start idle motion:', motionError);
                }
                
                // Add interactivity
                model.on('hit', (hitAreas) => {
                    console.log('Model hit detected:', hitAreas);
                    if (hitAreas.includes('Body')) {
                        try {
                            model.motion('Tap@Body');
                        } catch (tapError) {
                            console.warn('Failed to play Tap@Body motion:', tapError);
                            // Try alternative motion names based on the Hiyori model
                            const tapMotions = ['Tap', 'TapBody', 'Tap@Body', 'tap', 'Touch', 'motion'];
                            for (const motionName of tapMotions) {
                                try {
                                    model.motion(motionName);
                                    console.log('Played alternative motion:', motionName);
                                    break;
                                } catch (altTapError) {
                                    console.warn('Failed to play motion:', motionName, altTapError);
                                }
                            }
                        }
                    }
                });
                
                // Add mouse move interaction for better visibility
                app.renderer.plugins.interaction.on('pointermove', (event) => {
                    if (model) {
                        const point = event.data.global;
                        model.focus(point.x, point.y);
                    }
                });
                
                // Start periodic idle animations and blinking
                startIdleAnimations();
                
                hideLoadingIndicator();
                
                // Add window resize listener with debounce for better performance
                let resizeTimeout;
                window.addEventListener('resize', () => {
                    clearTimeout(resizeTimeout);
                    resizeTimeout = setTimeout(() => {
                        positionModel();
                    }, 100); // Debounce resize events
                });
                
                console.log('Live2D model initialization completed successfully');
            } catch (error) {
                console.error('Failed to load Live2D model:', error);
                loadingIndicator.innerHTML = 'Error loading model: ' + error.message + '. Switching to fallback interface.';
                loadingIndicator.style.display = 'block';
                
                // Show fallback UI
                document.getElementById('fallback-ui').style.display = 'flex';
                document.getElementById('live2d-canvas').style.display = 'none';
                
                // Hide loading indicator after a delay
                setTimeout(() => {
                    loadingIndicator.style.display = 'none';
                }, 3000);
                
                console.log('Fallback interface activated');
            }
        }
        
        // Position and scale the model with improved responsive logic
        // Position and scale the model correctly
    function positionModel() {
        if (app && model) {
            // Resize the PIXI app renderer to match window size
            app.renderer.resize(window.innerWidth, window.innerHeight);
            
            // --- FIXES ---
            
            // 1. Position the model horizontally centered
            model.x = app.screen.width / 2;
            
            // 2. Scale the model so its height is about 85% of the screen height
            //    This makes her much larger and fills the space better.
            const scale = (app.screen.height / model.height) * 1.95; 
            model.scale.set(scale);

            // 3. Position the model vertically. 
            //    Place her anchor point (center) slightly below the middle 
            //    so she looks more grounded. Adjust the 0.6 value (between 0.5 and 1.0) 
            //    if you want her higher or lower.
            model.y = app.screen.height * 0.9; 
            
            // --- END FIXES ---

            // Ensure the model is visible (this was already correct)
            model.visible = true;
            
            console.log(`Model positioned at (${model.x.toFixed(0)}, ${model.y.toFixed(0)}) with scale ${scale.toFixed(2)}`);
        }
    }
    
    // Emotion detection function
    function detectEmotion(text) {
        const lowerText = text.toLowerCase();
        
        // Greeting detection
        if (/\b(hello|hi|hey)\b/.test(lowerText)) {
            return "greeting";
        }
        
        // Happy detection
        if (/\b(thank you|thanks|appreciate)\b/.test(lowerText)) {
            return "happy";
        }
        
        // Angry detection
        if (/\b(angry|mad|hate|stupid)\b/.test(lowerText)) {
            return "angry";
        }
        
        // Sad detection
        if (/\b(sad|cry|upset)\b/.test(lowerText)) {
            return "sad";
        }
        
        // Neutral by default
        return "neutral";
    }
    
    // Emotion mapping to expressions and motions
    const emotionMap = {
        greeting: { expression: null, motion: 'Tap@Body' }, // Waving motion
        happy:    { expression: null, motion: null },       // Could add a happy motion if available
        angry:    { expression: null, motion: 'Flick@Body' }, // Flick motion for anger
        sad:      { expression: null, motion: null },       // Could add a sad motion if available
        neutral:  { expression: null, motion: null }        // Default/Idle
    };
    
    // Enhanced facial expression function
    function setFacialExpression(emotion) {
        if (!model || !model.internalModel || !model.internalModel.coreModel) return;
        
        const coreModel = model.internalModel.coreModel;
        
        try {
            switch(emotion) {
                case 'happy':
                    // Happy expression: slightly open mouth, raised cheeks
                    coreModel.setParameterValue('ParamMouthForm', 0.5);
                    coreModel.setParameterValue('ParamCheek', 0.3);
                    coreModel.setParameterValue('ParamEyeLSmile', 1);
                    coreModel.setParameterValue('ParamEyeRSmile', 1);
                    break;
                case 'angry':
                    // Angry expression: furrowed brows, tight mouth
                    coreModel.setParameterValue('ParamBrowLForm', -0.5);
                    coreModel.setParameterValue('ParamBrowRForm', -0.5);
                    coreModel.setParameterValue('ParamMouthForm', -0.7);
                    coreModel.setParameterValue('ParamEyeBallY', 0.2);
                    break;
                case 'sad':
                    // Sad expression: downturned mouth, droopy eyes
                    coreModel.setParameterValue('ParamBrowLForm', -0.3);
                    coreModel.setParameterValue('ParamBrowRForm', -0.3);
                    coreModel.setParameterValue('ParamMouthForm', -0.5);
                    coreModel.setParameterValue('ParamEyeBallY', -0.2);
                    coreModel.setParameterValue('ParamCheek', 0.1);
                    break;
                case 'greeting':
                    // Greeting expression: friendly smile
                    coreModel.setParameterValue('ParamMouthForm', 0.3);
                    coreModel.setParameterValue('ParamEyeLSmile', 0.7);
                    coreModel.setParameterValue('ParamEyeRSmile', 0.7);
                    break;
                default:
                    // Neutral expression: reset parameters
                    coreModel.setParameterValue('ParamMouthForm', 0);
                    coreModel.setParameterValue('ParamCheek', 0);
                    coreModel.setParameterValue('ParamEyeLSmile', 0);
                    coreModel.setParameterValue('ParamEyeRSmile', 0);
                    coreModel.setParameterValue('ParamBrowLForm', 0);
                    coreModel.setParameterValue('ParamBrowRForm', 0);
                    coreModel.setParameterValue('ParamEyeBallY', 0);
            }
            console.log(`Set facial expression for emotion: ${emotion}`);
        } catch (error) {
            console.warn(`Failed to set facial expression for ${emotion}:`, error);
        }
    }
    
    // Enhanced eye tracking with more natural movement
    function enhanceEyeTracking() {
        if (!model) return;
        
        // Override the default focus behavior for more expressive eyes
        let lastEyeX = 0;
        let lastEyeY = 0;
        let isMouseMoving = false;
        let mouseMoveTimeout;
        
        // Track mouse movement
        app.renderer.plugins.interaction.on('pointermove', (event) => {
            if (model && model.internalModel && model.internalModel.coreModel) {
                isMouseMoving = true;
                clearTimeout(mouseMoveTimeout);
                
                // Set timeout to detect when mouse stops moving
                mouseMoveTimeout = setTimeout(() => {
                    isMouseMoving = false;
                }, 300); // Consider mouse stopped after 300ms of no movement
                
                const point = event.data.global;
                
                // Calculate relative position to model center
                const relX = (point.x - model.x) / (app.screen.width / 2);
                const relY = (point.y - model.y) / (app.screen.height / 2);
                
                // Apply smoothing to eye movement
                const smoothX = lastEyeX + (relX - lastEyeX) * 0.3;
                const smoothY = lastEyeY + (relY - lastEyeY) * 0.3;
                
                // Update last positions
                lastEyeX = smoothX;
                lastEyeY = smoothY;
                
                // Apply to eye parameters with enhanced range
                try {
                    const coreModel = model.internalModel.coreModel;
                    coreModel.setParameterValue('ParamEyeBallX', smoothX * 0.8);
                    coreModel.setParameterValue('ParamEyeBallY', smoothY * 0.6);
                } catch (error) {
                    // Fallback to default focus if direct parameter access fails
                    model.focus(point.x, point.y);
                }
            }
        });
        
        // Continuous subtle eye movements when mouse is not moving
        setInterval(() => {
            if (model && model.internalModel && model.internalModel.coreModel && !isMouseMoving) {
                try {
                    const coreModel = model.internalModel.coreModel;
                    
                    // Add subtle random eye movements
                    const randomX = (Math.random() * 0.2) - 0.1; // -0.1 to 0.1
                    const randomY = (Math.random() * 0.1) - 0.05; // -0.05 to 0.05
                    
                    // Apply to current eye positions with small adjustments
                    const currentX = coreModel.getParameterValue('ParamEyeBallX');
                    const currentY = coreModel.getParameterValue('ParamEyeBallY');
                    
                    coreModel.setParameterValue('ParamEyeBallX', currentX + randomX);
                    coreModel.setParameterValue('ParamEyeBallY', currentY + randomY);
                } catch (error) {
                    console.warn('Failed to apply subtle eye movements:', error);
                }
            }
        }, 1000); // Every second
    }
    
    // Start periodic idle animations and subtle movements
    function startIdleAnimations() {
        if (!model) return;
        
        // Enhanced periodic blinking with more natural pattern
        setInterval(() => {
            if (model && Math.random() > 0.3) { // 70% chance to blink
                blinkEyes();
            }
        }, 4000); // Every 4 seconds
        
        // Subtle head and body movements
        setInterval(() => {
            if (model && Math.random() > 0.4) { // 60% chance for subtle movement
                subtleMovements();
            }
        }, 3000); // Every 3 seconds
        
        // Continuous facial micro-expressions
        setInterval(() => {
            if (model && Math.random() > 0.5) { // 50% chance for micro-expression
                facialMicroExpressions();
            }
        }, 2500); // Every 2.5 seconds
        
        // Enhanced eye tracking
        enhanceEyeTracking();
        
        // Continuous breathing effect
        startBreathingEffect();
    }
    
    // Continuous breathing effect for more lifelike appearance
    function startBreathingEffect() {
        if (!model || !model.internalModel || !model.internalModel.coreModel) return;
        
        const coreModel = model.internalModel.coreModel;
        let breathPhase = 0;
        
        setInterval(() => {
            try {
                // Gentle breathing motion
                breathPhase += 0.05;
                const breath = Math.sin(breathPhase) * 0.3;
                
                // Apply to breathing parameter
                coreModel.setParameterValue('ParamBreath', breath);
                
                // Subtle chest movement
                coreModel.setParameterValue('ParamBodyAngleY', breath * 0.5);
            } catch (error) {
                console.warn('Failed to apply breathing effect:', error);
            }
        }, 100); // Update frequently for smooth animation
    }
    
    // Facial micro-expressions for continuous liveliness
    function facialMicroExpressions() {
        if (!model || !model.internalModel || !model.internalModel.coreModel) return;
        
        const coreModel = model.internalModel.coreModel;
        
        try {
            // Random micro-expression
            const expressionType = Math.floor(Math.random() * 4);
            
            switch(expressionType) {
                case 0: // Subtle smile
                    coreModel.setParameterValue('ParamEyeLSmile', 0.3);
                    coreModel.setParameterValue('ParamEyeRSmile', 0.3);
                    coreModel.setParameterValue('ParamMouthForm', 0.2);
                    setTimeout(() => {
                        coreModel.setParameterValue('ParamEyeLSmile', 0);
                        coreModel.setParameterValue('ParamEyeRSmile', 0);
                        coreModel.setParameterValue('ParamMouthForm', 0);
                    }, 800);
                    break;
                case 1: // Subtle brow raise
                    coreModel.setParameterValue('ParamBrowLForm', 0.2);
                    coreModel.setParameterValue('ParamBrowRForm', 0.2);
                    setTimeout(() => {
                        coreModel.setParameterValue('ParamBrowLForm', 0);
                        coreModel.setParameterValue('ParamBrowRForm', 0);
                    }, 600);
                    break;
                case 2: // Subtle cheek flush
                    coreModel.setParameterValue('ParamCheek', 0.1);
                    setTimeout(() => {
                        coreModel.setParameterValue('ParamCheek', 0);
                    }, 1000);
                    break;
                case 3: // Subtle eye movement
                    const eyeX = (Math.random() * 0.3) - 0.15;
                    const eyeY = (Math.random() * 0.2) - 0.1;
                    coreModel.setParameterValue('ParamEyeBallX', eyeX);
                    coreModel.setParameterValue('ParamEyeBallY', eyeY);
                    setTimeout(() => {
                        coreModel.setParameterValue('ParamEyeBallX', 0);
                        coreModel.setParameterValue('ParamEyeBallY', 0);
                    }, 700);
                    break;
            }
        } catch (error) {
            console.warn('Failed to apply micro-expression:', error);
        }
    }
    
    // Subtle head and body movements
    function subtleMovements() {
        if (!model || !model.internalModel || !model.internalModel.coreModel) return;
        
        const coreModel = model.internalModel.coreModel;
        try {
            // Random subtle movements
            const headX = (Math.random() * 4) - 2;  // -2 to 2 degrees
            const headY = (Math.random() * 3) - 1.5; // -1.5 to 1.5 degrees
            const headZ = (Math.random() * 2) - 1;   // -1 to 1 degrees
            const bodyX = (Math.random() * 2) - 1;   // -1 to 1 degrees
            
            // Apply movements gradually
            coreModel.setParameterValue('ParamAngleX', headX);
            coreModel.setParameterValue('ParamAngleY', headY);
            coreModel.setParameterValue('ParamAngleZ', headZ);
            coreModel.setParameterValue('ParamBodyAngleX', bodyX);
        } catch (error) {
            console.warn('Failed to apply subtle movements:', error);
        }
    }
    
    // Enhanced blinking function
    function blinkEyes() {
        if (!model || !model.internalModel || !model.internalModel.coreModel) return;
        
        const coreModel = model.internalModel.coreModel;
        try {
            // Get current eye openness values
            const leftEyeOpen = coreModel.getParameterValue('ParamEyeLOpen');
            const rightEyeOpen = coreModel.getParameterValue('ParamEyeROpen');
            
            // Close eyes quickly
            coreModel.setParameterValue('ParamEyeLOpen', 0);
            coreModel.setParameterValue('ParamEyeROpen', 0);
            
            // Hold for a short moment
            setTimeout(() => {
                // Half open
                coreModel.setParameterValue('ParamEyeLOpen', 0.5);
                coreModel.setParameterValue('ParamEyeROpen', 0.5);
                
                // Fully open after a brief moment
                setTimeout(() => {
                    coreModel.setParameterValue('ParamEyeLOpen', leftEyeOpen);
                    coreModel.setParameterValue('ParamEyeROpen', rightEyeOpen);
                }, 50);
            }, 80);
        } catch (error) {
            console.warn('Failed to blink eyes:', error);
        }
    }
    
    // Enhanced emotion-based animation function
    async function playEmotionAnimation(emotion) {
        if (!model) return;
        
        const emotionData = emotionMap[emotion];
        console.log(`Playing emotion animation for: ${emotion}`, emotionData);
        
        // Set facial expression first
        setFacialExpression(emotion);
        
        // Play motion if defined
        if (emotionData.motion) {
            try {
                console.log(`Playing motion: ${emotionData.motion}`);
                model.motion(emotionData.motion, undefined, 3); // Priority 3
            } catch (error) {
                console.warn(`Failed to play motion: ${emotionData.motion}`, error);
            }
        }
        
        // Special handling for greeting - add waving gesture
        if (emotion === 'greeting') {
            // Enhanced waving with arm motion
            waveHand();
        }
        
        // Wait a bit for the animation to play before speaking
        if (emotionData.motion || emotion === 'greeting') {
            // Wait for a short time to allow the motion to start
            await new Promise(resolve => setTimeout(resolve, 600));
        }
    }
    
    // Hand waving animation for greetings
    function waveHand() {
        if (!model || !model.internalModel || !model.internalModel.coreModel) return;
        
        const coreModel = model.internalModel.coreModel;
        try {
            // Animate arm parameters for waving
            const originalArmLA = coreModel.getParameterValue('ParamArmLA');
            
            // Wave motion - move arm up and down
            let waveCount = 0;
            const waveInterval = setInterval(() => {
                const waveValue = Math.sin(waveCount * 0.5) * 15 - 10;
                coreModel.setParameterValue('ParamArmLA', waveValue);
                waveCount++;
                
                if (waveCount > 12) { // About 1.2 seconds of waving
                    clearInterval(waveInterval);
                    // Return to original position
                    coreModel.setParameterValue('ParamArmLA', originalArmLA);
                }
            }, 100);
        } catch (error) {
            console.warn('Failed to wave hand:', error);
            
            // Fallback to motion if parameter animation fails
            try {
                model.motion('Tap@Body', undefined, 3);
            } catch (motionError) {
                console.warn('Failed to play fallback waving motion:', motionError);
            }
        }
    }
        
        // Show loading indicator
        function showLoadingIndicator() {
            loadingIndicator.style.display = 'block';
        }
        
        // Hide loading indicator
        function hideLoadingIndicator() {
            loadingIndicator.style.display = 'none';
        }
        
        // Send message handler
        async function sendMessage() {
            const message = messageInput.value.trim();
            if (!message) return;
            
            // Clear input
            messageInput.value = '';
            
            try {
                // Detect emotion from text
                const emotion = detectEmotion(message);
                console.log(`Detected emotion: ${emotion}`);
                
                // Play emotion-based animation
                await playEmotionAnimation(emotion);
                
                // Generate speech from text
                await generateSpeech(message);
                
                // Reset to neutral expression after speech
                setTimeout(() => {
                    setFacialExpression('neutral');
                }, 2000);
            } catch (error) {
                console.error('Error generating speech:', error);
                alert('Failed to generate speech. Please check console for details.');
            }
        }
        
        // Generate speech using ElevenLabs API with improved lip sync
        async function generateSpeech(text) {
            const apiKey = localStorage.getItem('elevenlabs-api-key');
            if (!apiKey) {
                alert('API key not found. Please enter your ElevenLabs API key.');
                apiKeyModal.style.display = 'flex';
                return;
            }
            
            try {
                // Show loading indicator
                showLoadingIndicator();
                loadingIndicator.innerHTML = 'Generating speech...';
                
                // Make API request with optimized settings for lip sync
                const response = await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${DEFAULT_VOICE_ID}`, {
                    method: 'POST',
                    headers: {
                        'Accept': 'audio/mpeg',
                        'Content-Type': 'application/json',
                        'xi-api-key': apiKey
                    },
                    body: JSON.stringify({
                        text: text,
                        model_id: 'eleven_monolingual_v1',
                        voice_settings: {
                            stability: 0.3,        // Reduced for more expressive speech
                            similarity_boost: 0.7, // Increased for clearer voice
                            style: 0.2,            // Added style parameter
                            useSpeakerBoost: true   // Added speaker boost
                        }
                    })
                });
                
                if (!response.ok) {
                    hideLoadingIndicator();
                    const errorData = await response.json();
                    throw new Error(`API request failed: ${errorData.detail?.message || response.statusText}`);
                }
                
                // Convert response to blob
                const audioBlob = await response.blob();
                
                // Create object URL for audio
                const audioUrl = URL.createObjectURL(audioBlob);
                
                // Play audio with lip-sync if model is available
                if (model && typeof model.speak === 'function') {
                    // Configure lip sync parameters for better synchronization
                    model.lipSync = true;
                    model.volume = 1.0;
                    
                    console.log('Playing speech with lip-sync');
                    
                    // Create a promise to handle when speech finishes
                    const speechPromise = new Promise((resolve) => {
                        // Create audio element to track when speech ends
                        const audio = new Audio(audioUrl);
                        audio.onended = () => {
                            resolve();
                        };
                        
                        // Also resolve after a maximum time to prevent hanging
                        setTimeout(() => {
                            resolve();
                        }, 10000); // 10 second timeout
                        
                        // Start speaking
                        model.speak(audioUrl);
                    });
                    
                    // Wait for speech to finish
                    await speechPromise;
                } else {
                    // Fallback: play audio without lip-sync
                    const audio = new Audio(audioUrl);
                    audio.play();
                    
                    // Wait for audio to finish
                    await new Promise((resolve) => {
                        audio.onended = () => {
                            resolve();
                        };
                        
                        // Also resolve after a maximum time to prevent hanging
                        setTimeout(() => {
                            resolve();
                        }, 10000); // 10 second timeout
                    });
                }
                
                // Hide loading indicator
                hideLoadingIndicator();
            } catch (error) {
                hideLoadingIndicator();
                console.error('Error generating speech:', error);
                alert('Failed to generate speech: ' + error.message + '. Please check your API key and try again.');
            }
        }
        
        // Event listeners
        sendButton.addEventListener('click', sendMessage);
        
        messageInput.addEventListener('keypress', (e) => {
            if (e.key === 'Enter') {
                sendMessage();
            }
        });
        
        // Initialize app if API key exists
        if (savedApiKey) {
            // Wait for libraries to fully load before initializing
            window.addEventListener('load', () => {
                setTimeout(initApp, 500);
            });
        } else {
            // If no API key, initialize anyway to show the model
            window.addEventListener('load', () => {
                setTimeout(initApp, 500);
            });
        }
    </script>
</body>
</html>